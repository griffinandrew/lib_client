#![feature(allocator_api)]



//! Direct client that uses the PaperCache library in-process (no network).
//!
//! Build and run this binary with the crate that contains `PaperCache`.
//! Example: `cargo run --bin direct_client --release -- <object_size> <max_memory_bytes> [config_str]`
use std::env;
use std::error::Error;
use std::fs::OpenOptions;
use std::io::Write;
use std::process::exit;
use std::time::Instant;

use rand::{rngs::ThreadRng, Rng, rng};
//use std::sync::Arc;

use paper_cache::{PaperCache, PaperPolicy, CacheError};

use core::alloc::{GlobalAlloc, Layout};

mod allocator_bindings {
    include!("umf_allocator_bindings.rs"); // generated by bindgen
}

static NUM_OBJECTS: u64 = 100_000_000;
static CONFIG: &str = "local";
static OBJECT_SIZE_BYTES: usize = 8; // default object size in bytes
static NUM_SAMPLES: usize = 200_000_000;
static MAX_MEMORY_BYTES: usize = 10 * 1024 * 1024 * 1024; // 10 GiB

// Make keys a fixed size in bytes (ASCII characters).
static KEY_SIZE_BYTES: usize = 16;

// Number of GETs to perform as warm-up (not recorded).
static WARMUP_GETS: usize = 100_000;

use typesize::TypeSize; // assuming the trait is from typesize crate


#[derive(Clone, Debug)]
pub struct PmemBuffer(Vec<u8, HybridObjects>);

impl PmemBuffer {
    pub fn new(capacity: usize, index: usize) -> Self {
        let mut v = Vec::with_capacity_in(capacity, HybridObjects);
        v.resize(capacity, 0);
        
        // Embed the index at the beginning of the buffer
        let index_bytes = index.to_le_bytes();
        let bytes_to_copy = index_bytes.len().min(capacity);
        v[..bytes_to_copy].copy_from_slice(&index_bytes[..bytes_to_copy]);
        
        //println!("PmemBuffer: allocated {} bytes with embedded index {}", capacity, index);
        //println!("PmemBuffer ptr: {:p}", v.as_ptr());
        Self(v)
    }
}

impl typesize::TypeSize for PmemBuffer {
    fn extra_size(&self) -> usize {
        self.0.capacity()
    }
}

//#[derive(typesize)]
//pub struct HybridVec(Vec<u8, HybridObjects>);

mod allocator;
use crate::allocator::HybridObjects;

// Output CSV file
static OUTPATH: &str = "/tmp/paper_direct_client_zero_copy.csv";

fn derive_number_of_objects(bytes: usize, max: usize) -> usize {
    if bytes == 0 {
        println!("object size cannot be zero");
        exit(1);
    }
    let number_of_objects = max / bytes;
    println!("derived number of objects: {}", number_of_objects);
    number_of_objects
}

/// Build a key string for the given index and pad/truncate it so its
/// UTF-8 byte length equals target_len. Pads with ASCII '0'.
fn make_padded_key(idx: usize, target_len: usize) -> String {
    let mut s = format!("key_{}", idx);
    let cur_len = s.len();
    if cur_len == target_len {
        s
    } else if cur_len > target_len {
        s.truncate(target_len);
        s
    } else {
        s.extend(std::iter::repeat('0').take(target_len - cur_len));
        s
    }
}

fn main() -> Result<(), Box<dyn Error>> {
    let args: Vec<String> = env::args().collect();

    let mut bytes = OBJECT_SIZE_BYTES;
    let mut number_of_objects = NUM_OBJECTS as usize;
    let mut config_str = String::from(CONFIG);
    let mut max_memory_bytes = MAX_MEMORY_BYTES;

    if args.len() != 4 {
        println!(
            "Usage: {} <object_size_bytes> <max_memory_bytes> [config_str]",
            args[0]
        );
        println!(
            "Using default parameters: object_size_bytes={}, max_memory_bytes={}, config_str={}",
            bytes, max_memory_bytes, config_str
        );
    }
    if args.len() > 3 {
        bytes = args[1].parse().expect("Argument must be a number");
        println!("bytes: {}", bytes);
        max_memory_bytes = args[2].parse().expect("Argument must be a number");
        println!("max_memory_bytes: {}", max_memory_bytes);

        number_of_objects = derive_number_of_objects(bytes, max_memory_bytes);
        println!("number_of_objects: {}", number_of_objects);
        config_str = args[3].clone();
        println!("config: {}", config_str);
    }

    // Initialize an in-process PaperCache<String, Vec<u8>>
    // Choose one or more policies; this example uses LFU only.
    //let cache = PaperCache::<String, Vec<u8>>::new(
    //let cache = PaperCache::<String, Vec<u8>, A>::new(
    //let cache = PaperCache::<String, Vec<u8, HybridObjects>>::new(
    let cache = PaperCache::<String, PmemBuffer>::new(
        (max_memory_bytes as u64).max(1), // paper_cache expects non-zero
        &[PaperPolicy::Lfu],
        PaperPolicy::Lfu,
    )?;
    // note: cache is shared by threads if needed; here we run single-threaded.

    // Template value filled with ASCII '0'
    let big_value = vec![b'0'; bytes];
   
	//let mut buf = vec![0u8; buf_size].into_boxed_slice();

	let mut pmem_buffer: Vec<u8, HybridObjects> = Vec::with_capacity_in(bytes, HybridObjects);
    pmem_buffer.resize(bytes, 0); // initialize with zeros
	
	//i think this moves it back to a dram allocated buffer....
	//no i think im worng as no error when building....
	//let mut pmem_buffer = pmem_buffer.into_boxed_slice();

    println!(
        "Warming up with {} objects of size {} bytes (initial SETs)...",
        number_of_objects, bytes
    );

    for i in 0..number_of_objects {
        let key = make_padded_key(i, KEY_SIZE_BYTES);
        //let mut pmem_buffer: Vec<u8, HybridObjects> = Vec::with_capacity_in(bytes, HybridObjects);
        //pmem_buffer.resize(bytes, 0); // initialize with zeros
        
        let pmem_buffer: PmemBuffer = PmemBuffer::new(bytes, i);

        if let Err(err) = cache.set(key, pmem_buffer, None) {
            // On set error, log and continue
            eprintln!("Warmup set failed: {err:?}");
        }

        /*
        let key_check = make_padded_key(i, KEY_SIZE_BYTES);
        if i % 10000 == 0 {
            if let Ok(retrieved) = cache.get(&key_check) {
                println!("Verified key {} has data pointer: {:p}", key_check, retrieved.0.as_ptr());
                let tier = unsafe { allocator_bindings::check_tier(retrieved.0.as_ptr() as *mut _) };
                println!("key={} is in tier {}", key_check, tier);
            }
        }
        */
    
    }

    let hot_fraction = 0.10;
    let hot_prob = 0.90;
    let hot_cutoff = (number_of_objects as f64 * hot_fraction) as usize;

    // RNG
    let mut rng: ThreadRng = rng();

    // Warm-up GETs (not recorded)
    if WARMUP_GETS > 0 {
        println!(
            "Performing {} warm-up GETs (90/10 sampling) before recording stats...",
            WARMUP_GETS
        );
        for _ in 0..WARMUP_GETS {
            let idx = select_index(&mut rng, number_of_objects, hot_cutoff, hot_prob);
            let key = make_padded_key(idx, KEY_SIZE_BYTES);
            if let Err(err) = cache.get(&key) {
                // Occasionally log errors to avoid spamming
                eprintln!("Warmup GET error: {err:?}");
            }
        }
        println!("Warm-up GETs complete.");
    }

    let mut latencies_ns: Vec<u128> = Vec::with_capacity(NUM_SAMPLES.min(number_of_objects));
    let mut successes: usize = 0usize;

    println!("Starting 90-10 GET test with {} objects...", number_of_objects);
    let total_start = Instant::now();

    for _ in 0..NUM_SAMPLES {
        let idx = select_index(&mut rng, number_of_objects, hot_cutoff, hot_prob);
        let key = make_padded_key(idx, KEY_SIZE_BYTES);
        let start = Instant::now();
        match cache.get(&key) {
            Ok(val_arc) => {
                // val_arc: Arc<Vec<u8>>
                let elapsed_ns = start.elapsed().as_nanos();
                latencies_ns.push(elapsed_ns);
                successes += 1;
                // Avoid printing the entire value for large objects; print length only
                //println!("GET success: key={} len={}", key, val_arc.len());
            }
            Err(err) => {
                eprintln!("GET error for key {}: {:?}", key, err);
            }
        }
    }

    let total_elapsed = total_start.elapsed().as_secs_f64();
    if successes == 0 {
        println!("No successful gets to compute statistics.");
        return Ok(());
    }

    // Compute latency stats
    latencies_ns.sort();
    let sum: u128 = latencies_ns.iter().copied().sum();
    let avg_ns = sum / (successes as u128);
    let min_ns = latencies_ns.first().copied().unwrap_or(0);
    let max_ns = latencies_ns.last().copied().unwrap_or(0);

    let percentile = |sorted: &Vec<u128>, p: f64| -> u128 {
        let n = sorted.len();
        if n == 0 {
            return 0;
        }
        let rank = (p * n as f64).ceil() as usize;
        let idx = (rank.saturating_sub(1)).min(n - 1);
        sorted[idx]
    };

    let p50 = percentile(&latencies_ns, 0.50);
    let p90 = percentile(&latencies_ns, 0.90);
    let p99 = percentile(&latencies_ns, 0.99);
    let p99999 = percentile(&latencies_ns, 0.99999);

    // Throughput and bandwidth
    let gets_per_sec = successes as f64 / total_elapsed;
    let bytes_transferred = successes as f64 * bytes as f64;
    let bandwidth_mb_s = bytes_transferred / (1024.0 * 1024.0) / total_elapsed;

    println!("========== Results ==========");
    println!("Samples: {}", successes);
    println!(
        "Avg: {} ns ({:.3} µs)\nMin: {} ns ({:.3} µs)\nMax: {} ns ({:.3} µs)",
        avg_ns,
        avg_ns as f64 / 1_000.0,
        min_ns,
        min_ns as f64 / 1_000.0,
        max_ns,
        max_ns as f64 / 1_000.0,
    );
    println!(
        "p50: {} ns ({:.3} µs)\n\
         p90: {} ns ({:.3} µs)\n\
         p99: {} ns ({:.3} µs)\n\
         p99.999: {} ns ({:.3} µs)",
        p50,
        p50 as f64 / 1_000.0,
        p90,
        p90 as f64 / 1_000.0,
        p99,
        p99 as f64 / 1_000.0,
        p99999,
        p99999 as f64 / 1_000.0,
    );
    println!("Throughput: {:.2} GETs/sec", gets_per_sec);
    println!("Bandwidth: {:.2} MB/s", bandwidth_mb_s);
    println!("=============================");

    // Write to CSV
    let out_path = OUTPATH;
    match OpenOptions::new().create(true).append(true).open(out_path) {
        Ok(mut file) => {
            if file.metadata().map(|m| m.len()).unwrap_or(0) == 0 {
                let header = "config,key_size,object_size,warmup_gets,samples,avg_ns,min_ns,max_ns,p50,p90,p99,p99999,gets_per_sec,bandwidth_MB_s\n";
                if let Err(e) = file.write_all(header.as_bytes()) {
                    eprintln!("Failed writing header to {}: {}", out_path, e);
                }
            }
            let line = format!(
                "{},{},{},{},{},{},{},{},{},{},{},{},{:.2},{:.2}\n",
                config_str,
                KEY_SIZE_BYTES,
                bytes,
                WARMUP_GETS,
                successes,
                avg_ns,
                min_ns,
                max_ns,
                p50,
                p90,
                p99,
                p99999,
                gets_per_sec,
                bandwidth_mb_s
            );
            if let Err(e) = file.write_all(line.as_bytes()) {
                eprintln!("Failed writing stats to {}: {}", out_path, e);
            }
        }
        Err(e) => eprintln!("Failed to open {} for writing: {}", out_path, e),
    }

    Ok(())
}

/// Helper to select an index according to a 90/10 hotspot distribution.
/// Handles edge cases when number_of_objects or hot_cutoff are small.
fn select_index(rng: &mut ThreadRng, number_of_objects: usize, hot_cutoff: usize, hot_prob: f64) -> usize {
    if number_of_objects == 0 {
        return 0;
    }
    if hot_cutoff == 0 || hot_cutoff >= number_of_objects {
        // no meaningful hot set -> uniform random
        return rng.random_range(0..number_of_objects);
    }
    if rng.random_bool(hot_prob) {
        rng.random_range(0..hot_cutoff)
    } else {
        rng.random_range(hot_cutoff..number_of_objects)
    }
}
